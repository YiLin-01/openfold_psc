[2024-05-29 17:01:28,659] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
orig_dtype: torch.float32
Using /jet/home/ylinf/.cache/torch_extensions/py39_cu116 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /jet/home/ylinf/.cache/torch_extensions/py39_cu116/evoformer_attn/build.ninja...
Building extension module evoformer_attn...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module evoformer_attn...
Time to load evoformer_attn op: 0.4755368232727051 seconds
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
[model !!!!!!!] AlphaFold(
  (input_embedder): InputEmbedder(
    (linear_tf_z_i): Linear(in_features=22, out_features=128, bias=True)
    (linear_tf_z_j): Linear(in_features=22, out_features=128, bias=True)
    (linear_tf_m): Linear(in_features=22, out_features=256, bias=True)
    (linear_msa_m): Linear(in_features=49, out_features=256, bias=True)
    (linear_relpos): Linear(in_features=65, out_features=128, bias=True)
  )
  (recycling_embedder): RecyclingEmbedder(
    (linear): Linear(in_features=15, out_features=128, bias=True)
    (layer_norm_m): LayerNorm()
    (layer_norm_z): LayerNorm()
  )
  (template_embedder): TemplateEmbedder(
    (template_single_embedder): TemplateSingleEmbedder(
      (linear_1): Linear(in_features=57, out_features=256, bias=True)
      (relu): ReLU()
      (linear_2): Linear(in_features=256, out_features=256, bias=True)
    )
    (template_pair_embedder): TemplatePairEmbedder(
      (linear): Linear(in_features=88, out_features=64, bias=True)
    )
    (template_pair_stack): TemplatePairStack(
      (blocks): ModuleList(
        (0): TemplatePairStackBlock(
          (dropout_row): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
          (dropout_col): DropoutColumnwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=64, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=64, out_features=64, bias=False)
              (linear_k): Linear(in_features=64, out_features=64, bias=False)
              (linear_v): Linear(in_features=64, out_features=64, bias=False)
              (linear_o): Linear(in_features=64, out_features=64, bias=True)
              (linear_g): Linear(in_features=64, out_features=64, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttentionEndingNode(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=64, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=64, out_features=64, bias=False)
              (linear_k): Linear(in_features=64, out_features=64, bias=False)
              (linear_v): Linear(in_features=64, out_features=64, bias=False)
              (linear_o): Linear(in_features=64, out_features=64, bias=True)
              (linear_g): Linear(in_features=64, out_features=64, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_z): Linear(in_features=64, out_features=64, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_a_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_g): Linear(in_features=64, out_features=64, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_z): Linear(in_features=64, out_features=64, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_a_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_g): Linear(in_features=64, out_features=64, bias=True)
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=64, out_features=128, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=128, out_features=64, bias=True)
          )
        )
        (1): TemplatePairStackBlock(
          (dropout_row): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
          (dropout_col): DropoutColumnwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=64, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=64, out_features=64, bias=False)
              (linear_k): Linear(in_features=64, out_features=64, bias=False)
              (linear_v): Linear(in_features=64, out_features=64, bias=False)
              (linear_o): Linear(in_features=64, out_features=64, bias=True)
              (linear_g): Linear(in_features=64, out_features=64, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttentionEndingNode(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=64, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=64, out_features=64, bias=False)
              (linear_k): Linear(in_features=64, out_features=64, bias=False)
              (linear_v): Linear(in_features=64, out_features=64, bias=False)
              (linear_o): Linear(in_features=64, out_features=64, bias=True)
              (linear_g): Linear(in_features=64, out_features=64, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_z): Linear(in_features=64, out_features=64, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_a_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_g): Linear(in_features=64, out_features=64, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_z): Linear(in_features=64, out_features=64, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_a_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_p): Linear(in_features=64, out_features=64, bias=True)
            (linear_b_g): Linear(in_features=64, out_features=64, bias=True)
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=64, out_features=128, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=128, out_features=64, bias=True)
          )
        )
      )
      (layer_norm): LayerNorm()
    )
    (template_pointwise_att): TemplatePointwiseAttention(
      (mha): Attention(
        (linear_q): Linear(in_features=128, out_features=64, bias=False)
        (linear_k): Linear(in_features=64, out_features=64, bias=False)
        (linear_v): Linear(in_features=64, out_features=64, bias=False)
        (linear_o): Linear(in_features=64, out_features=128, bias=True)
        (sigmoid): Sigmoid()
      )
    )
  )
  (extra_msa_embedder): ExtraMSAEmbedder(
    (linear): Linear(in_features=25, out_features=64, bias=True)
  )
  (extra_msa_stack): ExtraMSAStack(
    (blocks): ModuleList(
      (0): ExtraMSABlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=64, bias=False)
            (linear_v): Linear(in_features=64, out_features=64, bias=False)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=64, out_features=256, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=256, out_features=64, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=64, out_features=32, bias=True)
          (linear_2): Linear(in_features=64, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnGlobalAttention(
          (layer_norm_m): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (global_attention): GlobalAttention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=8, bias=False)
            (linear_v): Linear(in_features=64, out_features=8, bias=False)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
      )
      (1): ExtraMSABlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=64, bias=False)
            (linear_v): Linear(in_features=64, out_features=64, bias=False)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=64, out_features=256, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=256, out_features=64, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=64, out_features=32, bias=True)
          (linear_2): Linear(in_features=64, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnGlobalAttention(
          (layer_norm_m): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (global_attention): GlobalAttention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=8, bias=False)
            (linear_v): Linear(in_features=64, out_features=8, bias=False)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
      )
      (2): ExtraMSABlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=64, bias=False)
            (linear_v): Linear(in_features=64, out_features=64, bias=False)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=64, out_features=256, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=256, out_features=64, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=64, out_features=32, bias=True)
          (linear_2): Linear(in_features=64, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnGlobalAttention(
          (layer_norm_m): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (global_attention): GlobalAttention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=8, bias=False)
            (linear_v): Linear(in_features=64, out_features=8, bias=False)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
      )
      (3): ExtraMSABlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=64, bias=False)
            (linear_v): Linear(in_features=64, out_features=64, bias=False)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=64, out_features=256, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=256, out_features=64, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=64, out_features=32, bias=True)
          (linear_2): Linear(in_features=64, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnGlobalAttention(
          (layer_norm_m): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (global_attention): GlobalAttention(
            (linear_q): Linear(in_features=64, out_features=64, bias=False)
            (linear_k): Linear(in_features=64, out_features=8, bias=False)
            (linear_v): Linear(in_features=64, out_features=8, bias=False)
            (linear_g): Linear(in_features=64, out_features=64, bias=True)
            (linear_o): Linear(in_features=64, out_features=64, bias=True)
            (sigmoid): Sigmoid()
          )
        )
      )
    )
  )
  (evoformer): EvoformerStack(
    (blocks): ModuleList(
      (0): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (1): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (2): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (3): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (4): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (5): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (6): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (7): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (8): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (9): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (10): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (11): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (12): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (13): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (14): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (15): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (16): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (17): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (18): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (19): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (20): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (21): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (22): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (23): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (24): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (25): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (26): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (27): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (28): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (29): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (30): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (31): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (32): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (33): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (34): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (35): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (36): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (37): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (38): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (39): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (40): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (41): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (42): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (43): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (44): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (45): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (46): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
      (47): EvoformerBlock(
        (msa_att_row): MSARowAttentionWithPairBias(
          (layer_norm_m): LayerNorm()
          (layer_norm_z): LayerNorm()
          (linear_z): Linear(in_features=128, out_features=8, bias=False)
          (mha): Attention(
            (linear_q): Linear(in_features=256, out_features=256, bias=False)
            (linear_k): Linear(in_features=256, out_features=256, bias=False)
            (linear_v): Linear(in_features=256, out_features=256, bias=False)
            (linear_o): Linear(in_features=256, out_features=256, bias=True)
            (linear_g): Linear(in_features=256, out_features=256, bias=True)
            (sigmoid): Sigmoid()
          )
        )
        (msa_dropout_layer): DropoutRowwise(
          (dropout): Dropout(p=0.15, inplace=False)
        )
        (msa_transition): MSATransition(
          (layer_norm): LayerNorm()
          (linear_1): Linear(in_features=256, out_features=1024, bias=True)
          (relu): ReLU()
          (linear_2): Linear(in_features=1024, out_features=256, bias=True)
        )
        (outer_product_mean): OuterProductMean(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_1): Linear(in_features=256, out_features=32, bias=True)
          (linear_2): Linear(in_features=256, out_features=32, bias=True)
          (linear_out): Linear(in_features=1024, out_features=128, bias=True)
        )
        (pair_stack): PairStack(
          (tri_mul_out): TriangleMultiplicationOutgoing(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_mul_in): TriangleMultiplicationIncoming(
            (linear_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_z): Linear(in_features=128, out_features=128, bias=True)
            (layer_norm_in): LayerNorm()
            (layer_norm_out): LayerNorm()
            (sigmoid): Sigmoid()
            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)
            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)
          )
          (tri_att_start): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (tri_att_end): TriangleAttention(
            (layer_norm): LayerNorm()
            (linear): Linear(in_features=128, out_features=4, bias=False)
            (mha): Attention(
              (linear_q): Linear(in_features=128, out_features=128, bias=False)
              (linear_k): Linear(in_features=128, out_features=128, bias=False)
              (linear_v): Linear(in_features=128, out_features=128, bias=False)
              (linear_o): Linear(in_features=128, out_features=128, bias=True)
              (linear_g): Linear(in_features=128, out_features=128, bias=True)
              (sigmoid): Sigmoid()
            )
          )
          (pair_transition): PairTransition(
            (layer_norm): LayerNorm()
            (linear_1): Linear(in_features=128, out_features=512, bias=True)
            (relu): ReLU()
            (linear_2): Linear(in_features=512, out_features=128, bias=True)
          )
          (ps_dropout_row_layer): DropoutRowwise(
            (dropout): Dropout(p=0.25, inplace=False)
          )
        )
        (msa_att_col): MSAColumnAttention(
          (_msa_att): MSAAttention(
            (layer_norm_m): LayerNorm()
            (mha): Attention(
              (linear_q): Linear(in_features=256, out_features=256, bias=False)
              (linear_k): Linear(in_features=256, out_features=256, bias=False)
              (linear_v): Linear(in_features=256, out_features=256, bias=False)
              (linear_o): Linear(in_features=256, out_features=256, bias=True)
              (linear_g): Linear(in_features=256, out_features=256, bias=True)
              (sigmoid): Sigmoid()
            )
          )
        )
      )
    )
    (linear): Linear(in_features=256, out_features=384, bias=True)
  )
  (structure_module): StructureModule(
    (layer_norm_s): LayerNorm()
    (layer_norm_z): LayerNorm()
    (linear_in): Linear(in_features=384, out_features=384, bias=True)
    (ipa): InvariantPointAttention(
      (linear_q): Linear(in_features=384, out_features=192, bias=True)
      (linear_q_points): PointProjection(
        (linear): Linear(in_features=384, out_features=144, bias=True)
      )
      (linear_kv): Linear(in_features=384, out_features=384, bias=True)
      (linear_kv_points): PointProjection(
        (linear): Linear(in_features=384, out_features=432, bias=True)
      )
      (linear_b): Linear(in_features=128, out_features=12, bias=True)
      (linear_out): Linear(in_features=2112, out_features=384, bias=True)
      (softmax): Softmax(dim=-1)
      (softplus): Softplus(beta=1, threshold=20)
    )
    (ipa_dropout): Dropout(p=0.1, inplace=False)
    (layer_norm_ipa): LayerNorm()
    (transition): StructureModuleTransition(
      (layers): ModuleList(
        (0): StructureModuleTransitionLayer(
          (linear_1): Linear(in_features=384, out_features=384, bias=True)
          (linear_2): Linear(in_features=384, out_features=384, bias=True)
          (linear_3): Linear(in_features=384, out_features=384, bias=True)
          (relu): ReLU()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (layer_norm): LayerNorm()
    )
    (bb_update): BackboneUpdate(
      (linear): Linear(in_features=384, out_features=6, bias=True)
    )
    (angle_resnet): AngleResnet(
      (linear_in): Linear(in_features=384, out_features=128, bias=True)
      (linear_initial): Linear(in_features=384, out_features=128, bias=True)
      (layers): ModuleList(
        (0): AngleResnetBlock(
          (linear_1): Linear(in_features=128, out_features=128, bias=True)
          (linear_2): Linear(in_features=128, out_features=128, bias=True)
          (relu): ReLU()
        )
        (1): AngleResnetBlock(
          (linear_1): Linear(in_features=128, out_features=128, bias=True)
          (linear_2): Linear(in_features=128, out_features=128, bias=True)
          (relu): ReLU()
        )
      )
      (linear_out): Linear(in_features=128, out_features=14, bias=True)
      (relu): ReLU()
    )
  )
  (aux_heads): AuxiliaryHeads(
    (plddt): PerResidueLDDTCaPredictor(
      (layer_norm): LayerNorm()
      (linear_1): Linear(in_features=384, out_features=128, bias=True)
      (linear_2): Linear(in_features=128, out_features=128, bias=True)
      (linear_3): Linear(in_features=128, out_features=50, bias=True)
      (relu): ReLU()
    )
    (distogram): DistogramHead(
      (linear): Linear(in_features=128, out_features=64, bias=True)
    )
    (masked_msa): MaskedMSAHead(
      (linear): Linear(in_features=256, out_features=23, bias=True)
    )
    (experimentally_resolved): ExperimentallyResolvedHead(
      (linear): Linear(in_features=384, out_features=37, bias=True)
    )
    (tm): TMScoreHead(
      (linear): Linear(in_features=128, out_features=64, bias=True)
    )
  )
)
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32
orig_dtype: torch.float32

Test(s) failed. Make sure you've installed all Python dependencies.
